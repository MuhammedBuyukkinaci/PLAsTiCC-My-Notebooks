{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import lightgbm as lgb\n",
    "import itertools\n",
    "import pickle, gzip\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Reading train_metadata_kaggle & test_metadata_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 51) (3492890, 50)\n",
      "CPU times: user 1min 21s, sys: 5.31 s, total: 1min 26s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_metadata_kaggle = dd.read_csv('train_metadata_kaggle.csv')\n",
    "test_metadata_kaggle = dd.read_csv('test_metadata_kaggle.csv')\n",
    "train_metadata_kaggle = train_metadata_kaggle.compute()\n",
    "test_metadata_kaggle = test_metadata_kaggle.compute()\n",
    "print(train_metadata_kaggle.shape,test_metadata_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_metadata_kaggle['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 51) (3492890, 50)\n"
     ]
    }
   ],
   "source": [
    "print(train_metadata_kaggle.shape,test_metadata_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>flux_skew</th>\n",
       "      <th>flux_err_min</th>\n",
       "      <th>flux_err_max</th>\n",
       "      <th>flux_err_mean</th>\n",
       "      <th>flux_err_median</th>\n",
       "      <th>flux_err_std</th>\n",
       "      <th>flux_err_skew</th>\n",
       "      <th>detected_mean</th>\n",
       "      <th>flux_ratio_sq_sum</th>\n",
       "      <th>flux_ratio_sq_skew</th>\n",
       "      <th>flux_by_flux_ratio_sq_sum</th>\n",
       "      <th>flux_by_flux_ratio_sq_skew</th>\n",
       "      <th>flux_diff</th>\n",
       "      <th>flux_dif2</th>\n",
       "      <th>flux_w_mean</th>\n",
       "      <th>flux_dif3</th>\n",
       "      <th>0__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>0__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>0__kurtosis</th>\n",
       "      <th>0__skewness</th>\n",
       "      <th>1__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>1__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>1__kurtosis</th>\n",
       "      <th>1__skewness</th>\n",
       "      <th>2__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>2__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>2__kurtosis</th>\n",
       "      <th>2__skewness</th>\n",
       "      <th>3__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>3__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>3__kurtosis</th>\n",
       "      <th>3__skewness</th>\n",
       "      <th>4__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>4__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>4__kurtosis</th>\n",
       "      <th>4__skewness</th>\n",
       "      <th>5__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>5__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>5__kurtosis</th>\n",
       "      <th>5__skewness</th>\n",
       "      <th>mjd_diff_det</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>mwebv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>-12.680235</td>\n",
       "      <td>42.765503</td>\n",
       "      <td>3.997127</td>\n",
       "      <td>0.616561</td>\n",
       "      <td>9.149645</td>\n",
       "      <td>2.037355</td>\n",
       "      <td>0.691634</td>\n",
       "      <td>11.257108</td>\n",
       "      <td>2.461810</td>\n",
       "      <td>1.972973</td>\n",
       "      <td>1.718101</td>\n",
       "      <td>1.826388</td>\n",
       "      <td>0.157576</td>\n",
       "      <td>7806.412424</td>\n",
       "      <td>4.771625</td>\n",
       "      <td>1.896346e+05</td>\n",
       "      <td>5.396523</td>\n",
       "      <td>55.445738</td>\n",
       "      <td>13.871398</td>\n",
       "      <td>24.292155</td>\n",
       "      <td>2.282455</td>\n",
       "      <td>29.002872</td>\n",
       "      <td>37.684425</td>\n",
       "      <td>-0.247160</td>\n",
       "      <td>0.147622</td>\n",
       "      <td>92.039690</td>\n",
       "      <td>79.990817</td>\n",
       "      <td>10.567412</td>\n",
       "      <td>3.117684</td>\n",
       "      <td>164.640622</td>\n",
       "      <td>139.733762</td>\n",
       "      <td>4.512783</td>\n",
       "      <td>2.171455</td>\n",
       "      <td>300.547278</td>\n",
       "      <td>246.788411</td>\n",
       "      <td>2.951479</td>\n",
       "      <td>1.806797</td>\n",
       "      <td>408.305525</td>\n",
       "      <td>349.008202</td>\n",
       "      <td>0.094963</td>\n",
       "      <td>1.153076</td>\n",
       "      <td>324.515880</td>\n",
       "      <td>251.116361</td>\n",
       "      <td>0.072799</td>\n",
       "      <td>0.804929</td>\n",
       "      <td>119.8531</td>\n",
       "      <td>0.3193</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>-11.142164</td>\n",
       "      <td>14.839427</td>\n",
       "      <td>0.884047</td>\n",
       "      <td>0.072856</td>\n",
       "      <td>3.399946</td>\n",
       "      <td>0.970525</td>\n",
       "      <td>0.690589</td>\n",
       "      <td>11.249375</td>\n",
       "      <td>2.457580</td>\n",
       "      <td>1.973559</td>\n",
       "      <td>1.717591</td>\n",
       "      <td>1.826703</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>806.406927</td>\n",
       "      <td>11.486148</td>\n",
       "      <td>5.525817e+03</td>\n",
       "      <td>12.348124</td>\n",
       "      <td>25.981591</td>\n",
       "      <td>29.389389</td>\n",
       "      <td>6.852393</td>\n",
       "      <td>3.791608</td>\n",
       "      <td>22.708482</td>\n",
       "      <td>26.159787</td>\n",
       "      <td>0.099267</td>\n",
       "      <td>0.502325</td>\n",
       "      <td>13.685195</td>\n",
       "      <td>27.630359</td>\n",
       "      <td>13.429229</td>\n",
       "      <td>3.109318</td>\n",
       "      <td>31.012899</td>\n",
       "      <td>33.427074</td>\n",
       "      <td>13.769006</td>\n",
       "      <td>3.247873</td>\n",
       "      <td>56.042403</td>\n",
       "      <td>59.784625</td>\n",
       "      <td>1.750840</td>\n",
       "      <td>1.082798</td>\n",
       "      <td>83.561278</td>\n",
       "      <td>77.494564</td>\n",
       "      <td>-0.322108</td>\n",
       "      <td>-0.099957</td>\n",
       "      <td>84.725142</td>\n",
       "      <td>27.013154</td>\n",
       "      <td>-0.348744</td>\n",
       "      <td>0.132025</td>\n",
       "      <td>28.0053</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>-14.202744</td>\n",
       "      <td>16.761280</td>\n",
       "      <td>0.791032</td>\n",
       "      <td>0.458390</td>\n",
       "      <td>3.886578</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.663680</td>\n",
       "      <td>11.278636</td>\n",
       "      <td>2.702947</td>\n",
       "      <td>2.184483</td>\n",
       "      <td>1.922641</td>\n",
       "      <td>1.802497</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>784.835502</td>\n",
       "      <td>9.509911</td>\n",
       "      <td>4.124400e+03</td>\n",
       "      <td>9.923556</td>\n",
       "      <td>30.964024</td>\n",
       "      <td>39.143819</td>\n",
       "      <td>5.255113</td>\n",
       "      <td>5.892170</td>\n",
       "      <td>6.030862</td>\n",
       "      <td>46.450439</td>\n",
       "      <td>0.590786</td>\n",
       "      <td>-0.427429</td>\n",
       "      <td>53.366119</td>\n",
       "      <td>41.192678</td>\n",
       "      <td>4.127763</td>\n",
       "      <td>1.710048</td>\n",
       "      <td>58.607170</td>\n",
       "      <td>42.353288</td>\n",
       "      <td>8.642889</td>\n",
       "      <td>2.570936</td>\n",
       "      <td>26.975615</td>\n",
       "      <td>59.958041</td>\n",
       "      <td>3.484929</td>\n",
       "      <td>1.141959</td>\n",
       "      <td>57.222812</td>\n",
       "      <td>72.448018</td>\n",
       "      <td>2.085327</td>\n",
       "      <td>0.429582</td>\n",
       "      <td>76.240782</td>\n",
       "      <td>73.533783</td>\n",
       "      <td>0.063837</td>\n",
       "      <td>-0.175525</td>\n",
       "      <td>2.7628</td>\n",
       "      <td>0.8297</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>-12.631923</td>\n",
       "      <td>28.061138</td>\n",
       "      <td>0.970396</td>\n",
       "      <td>0.465986</td>\n",
       "      <td>4.100713</td>\n",
       "      <td>2.177402</td>\n",
       "      <td>0.697639</td>\n",
       "      <td>11.305429</td>\n",
       "      <td>2.480364</td>\n",
       "      <td>2.003704</td>\n",
       "      <td>1.723367</td>\n",
       "      <td>1.821626</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>876.027511</td>\n",
       "      <td>8.010597</td>\n",
       "      <td>8.293673e+03</td>\n",
       "      <td>9.227223</td>\n",
       "      <td>40.693061</td>\n",
       "      <td>41.934474</td>\n",
       "      <td>9.467365</td>\n",
       "      <td>4.298245</td>\n",
       "      <td>0.776942</td>\n",
       "      <td>14.926490</td>\n",
       "      <td>-0.580529</td>\n",
       "      <td>-0.058688</td>\n",
       "      <td>2.371129</td>\n",
       "      <td>22.476077</td>\n",
       "      <td>1.429683</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>34.447730</td>\n",
       "      <td>14.240274</td>\n",
       "      <td>1.223998</td>\n",
       "      <td>0.468594</td>\n",
       "      <td>58.911457</td>\n",
       "      <td>62.709899</td>\n",
       "      <td>4.269139</td>\n",
       "      <td>1.414380</td>\n",
       "      <td>115.918277</td>\n",
       "      <td>70.371095</td>\n",
       "      <td>7.377841</td>\n",
       "      <td>2.409871</td>\n",
       "      <td>112.547521</td>\n",
       "      <td>123.413344</td>\n",
       "      <td>1.793238</td>\n",
       "      <td>0.953107</td>\n",
       "      <td>3.0125</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>-13.239577</td>\n",
       "      <td>124.475609</td>\n",
       "      <td>4.580070</td>\n",
       "      <td>0.301366</td>\n",
       "      <td>19.862714</td>\n",
       "      <td>4.537527</td>\n",
       "      <td>0.679312</td>\n",
       "      <td>11.365292</td>\n",
       "      <td>2.746784</td>\n",
       "      <td>2.210577</td>\n",
       "      <td>1.930790</td>\n",
       "      <td>1.798629</td>\n",
       "      <td>0.065341</td>\n",
       "      <td>47612.580669</td>\n",
       "      <td>9.140568</td>\n",
       "      <td>4.815012e+06</td>\n",
       "      <td>10.251332</td>\n",
       "      <td>137.715186</td>\n",
       "      <td>30.068359</td>\n",
       "      <td>101.128982</td>\n",
       "      <td>1.361778</td>\n",
       "      <td>65.064185</td>\n",
       "      <td>55.191226</td>\n",
       "      <td>7.457425</td>\n",
       "      <td>2.135457</td>\n",
       "      <td>202.641918</td>\n",
       "      <td>191.410916</td>\n",
       "      <td>16.393710</td>\n",
       "      <td>4.133929</td>\n",
       "      <td>425.940451</td>\n",
       "      <td>414.455381</td>\n",
       "      <td>15.206929</td>\n",
       "      <td>4.036551</td>\n",
       "      <td>368.228927</td>\n",
       "      <td>360.630612</td>\n",
       "      <td>15.386561</td>\n",
       "      <td>4.030676</td>\n",
       "      <td>377.744797</td>\n",
       "      <td>301.983950</td>\n",
       "      <td>15.302549</td>\n",
       "      <td>3.992740</td>\n",
       "      <td>172.564336</td>\n",
       "      <td>289.757599</td>\n",
       "      <td>12.507289</td>\n",
       "      <td>3.513977</td>\n",
       "      <td>25.0572</td>\n",
       "      <td>0.4617</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id   flux_min    flux_max  flux_mean  flux_median   flux_std  \\\n",
       "0         13 -12.680235   42.765503   3.997127     0.616561   9.149645   \n",
       "1         14 -11.142164   14.839427   0.884047     0.072856   3.399946   \n",
       "2         17 -14.202744   16.761280   0.791032     0.458390   3.886578   \n",
       "3         23 -12.631923   28.061138   0.970396     0.465986   4.100713   \n",
       "4         34 -13.239577  124.475609   4.580070     0.301366  19.862714   \n",
       "\n",
       "   flux_skew  flux_err_min  flux_err_max  flux_err_mean  flux_err_median  \\\n",
       "0   2.037355      0.691634     11.257108       2.461810         1.972973   \n",
       "1   0.970525      0.690589     11.249375       2.457580         1.973559   \n",
       "2   0.377131      0.663680     11.278636       2.702947         2.184483   \n",
       "3   2.177402      0.697639     11.305429       2.480364         2.003704   \n",
       "4   4.537527      0.679312     11.365292       2.746784         2.210577   \n",
       "\n",
       "   flux_err_std  flux_err_skew  detected_mean  flux_ratio_sq_sum  \\\n",
       "0      1.718101       1.826388       0.157576        7806.412424   \n",
       "1      1.717591       1.826703       0.012121         806.406927   \n",
       "2      1.922641       1.802497       0.014205         784.835502   \n",
       "3      1.723367       1.821626       0.018182         876.027511   \n",
       "4      1.930790       1.798629       0.065341       47612.580669   \n",
       "\n",
       "   flux_ratio_sq_skew  flux_by_flux_ratio_sq_sum  flux_by_flux_ratio_sq_skew  \\\n",
       "0            4.771625               1.896346e+05                    5.396523   \n",
       "1           11.486148               5.525817e+03                   12.348124   \n",
       "2            9.509911               4.124400e+03                    9.923556   \n",
       "3            8.010597               8.293673e+03                    9.227223   \n",
       "4            9.140568               4.815012e+06                   10.251332   \n",
       "\n",
       "    flux_diff  flux_dif2  flux_w_mean  flux_dif3  \\\n",
       "0   55.445738  13.871398    24.292155   2.282455   \n",
       "1   25.981591  29.389389     6.852393   3.791608   \n",
       "2   30.964024  39.143819     5.255113   5.892170   \n",
       "3   40.693061  41.934474     9.467365   4.298245   \n",
       "4  137.715186  30.068359   101.128982   1.361778   \n",
       "\n",
       "   0__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                                29.002872   \n",
       "1                                22.708482   \n",
       "2                                 6.030862   \n",
       "3                                 0.776942   \n",
       "4                                65.064185   \n",
       "\n",
       "   0__fft_coefficient__coeff_1__attr_\"abs\"  0__kurtosis  0__skewness  \\\n",
       "0                                37.684425    -0.247160     0.147622   \n",
       "1                                26.159787     0.099267     0.502325   \n",
       "2                                46.450439     0.590786    -0.427429   \n",
       "3                                14.926490    -0.580529    -0.058688   \n",
       "4                                55.191226     7.457425     2.135457   \n",
       "\n",
       "   1__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                                92.039690   \n",
       "1                                13.685195   \n",
       "2                                53.366119   \n",
       "3                                 2.371129   \n",
       "4                               202.641918   \n",
       "\n",
       "   1__fft_coefficient__coeff_1__attr_\"abs\"  1__kurtosis  1__skewness  \\\n",
       "0                                79.990817    10.567412     3.117684   \n",
       "1                                27.630359    13.429229     3.109318   \n",
       "2                                41.192678     4.127763     1.710048   \n",
       "3                                22.476077     1.429683    -0.000571   \n",
       "4                               191.410916    16.393710     4.133929   \n",
       "\n",
       "   2__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                               164.640622   \n",
       "1                                31.012899   \n",
       "2                                58.607170   \n",
       "3                                34.447730   \n",
       "4                               425.940451   \n",
       "\n",
       "   2__fft_coefficient__coeff_1__attr_\"abs\"  2__kurtosis  2__skewness  \\\n",
       "0                               139.733762     4.512783     2.171455   \n",
       "1                                33.427074    13.769006     3.247873   \n",
       "2                                42.353288     8.642889     2.570936   \n",
       "3                                14.240274     1.223998     0.468594   \n",
       "4                               414.455381    15.206929     4.036551   \n",
       "\n",
       "   3__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                               300.547278   \n",
       "1                                56.042403   \n",
       "2                                26.975615   \n",
       "3                                58.911457   \n",
       "4                               368.228927   \n",
       "\n",
       "   3__fft_coefficient__coeff_1__attr_\"abs\"  3__kurtosis  3__skewness  \\\n",
       "0                               246.788411     2.951479     1.806797   \n",
       "1                                59.784625     1.750840     1.082798   \n",
       "2                                59.958041     3.484929     1.141959   \n",
       "3                                62.709899     4.269139     1.414380   \n",
       "4                               360.630612    15.386561     4.030676   \n",
       "\n",
       "   4__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                               408.305525   \n",
       "1                                83.561278   \n",
       "2                                57.222812   \n",
       "3                               115.918277   \n",
       "4                               377.744797   \n",
       "\n",
       "   4__fft_coefficient__coeff_1__attr_\"abs\"  4__kurtosis  4__skewness  \\\n",
       "0                               349.008202     0.094963     1.153076   \n",
       "1                                77.494564    -0.322108    -0.099957   \n",
       "2                                72.448018     2.085327     0.429582   \n",
       "3                                70.371095     7.377841     2.409871   \n",
       "4                               301.983950    15.302549     3.992740   \n",
       "\n",
       "   5__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                               324.515880   \n",
       "1                                84.725142   \n",
       "2                                76.240782   \n",
       "3                               112.547521   \n",
       "4                               172.564336   \n",
       "\n",
       "   5__fft_coefficient__coeff_1__attr_\"abs\"  5__kurtosis  5__skewness  \\\n",
       "0                               251.116361     0.072799     0.804929   \n",
       "1                                27.013154    -0.348744     0.132025   \n",
       "2                                73.533783     0.063837    -0.175525   \n",
       "3                               123.413344     1.793238     0.953107   \n",
       "4                               289.757599    12.507289     3.513977   \n",
       "\n",
       "   mjd_diff_det  hostgal_photoz  hostgal_photoz_err  mwebv  \n",
       "0      119.8531          0.3193              0.0542  0.019  \n",
       "1       28.0053          0.6323              0.0179  0.018  \n",
       "2        2.7628          0.8297              0.0605  0.016  \n",
       "3        3.0125          0.6533              0.1479  0.023  \n",
       "4       25.0572          0.4617              0.0122  0.023  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metadata_kaggle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) reading train_metadata_final & test_metadata_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "train_metadata = dd.read_csv('train_metadata_final.csv')\n",
    "test_metadata = dd.read_csv('test_metadata_final.csv')\n",
    "train_metadata = train_metadata.compute()\n",
    "test_metadata = test_metadata.compute()\n",
    "print(train_metadata.shape,test_metadata.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"y = train_metadata['target']\n",
    "del train_metadata['target']\n",
    "gc.collect()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Reading created_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_column = pd.read_csv('hostgal_specz.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_column.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_column.shape[0] == train_metadata_kaggle.shape[0] + test_metadata_kaggle.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_column.columns = ['object_id','hostgal_specz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_metadata_kaggle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Removing duplicated_columns from train_metadata & test_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "will_be_deleted_columns = ['NG_min_flux','NG_max_flux','NG_std_flux','NG_mean_flux','NG_median_flux',\n",
    "                          'NG_min_flux_err','NG_max_flux_err','NG_std_flux_err','NG_mean_flux_err','NG_median_flux_err',\n",
    "                          'NG_mean_detected','hostgal_photoz','hostgal_photoz_err','mwebv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "train_metadata.drop(will_be_deleted_columns,inplace=True , axis=1)\n",
    "test_metadata.drop(will_be_deleted_columns,inplace=True , axis=1)\n",
    "gc.collect()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_metadata_kaggle.shape,test_metadata_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,j in enumerate(list(train_metadata.columns.values)):\n",
    "#    print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Adding hostgal_specz to train_metadata_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "train_metadata_kaggle = train_metadata_kaggle.merge(right = created_column ,how='left',on = 'object_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Adding hostgal_specz to train_metadata_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "test_metadata_kaggle = test_metadata_kaggle.merge(right = created_column ,how='left',on = 'object_id')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_metadata_kaggle.shape,test_metadata_kaggle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Creating train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_columns = ['ra','decl','gal_l','gal_b','ddf','hostgal_specz','distmod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = train_metadata_kaggle.merge(right = train_metadata[[x for x in train_metadata.columns if x not in ignored_columns ]] ,how='left',on = 'object_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_metadata_kaggle['flux_diff_btw_mean_and_min'] = train_metadata_kaggle['flux_mean'] - train_metadata_kaggle['flux_min']\n",
    "train_metadata_kaggle['flux_diff_btw_mean_and_max'] = train_metadata_kaggle['flux_max'] - train_metadata_kaggle['flux_mean']\n",
    "\n",
    "#test\n",
    "test_metadata_kaggle['flux_diff_btw_mean_and_min'] = test_metadata_kaggle['flux_mean'] - test_metadata_kaggle['flux_min']\n",
    "test_metadata_kaggle['flux_diff_btw_mean_and_max'] = test_metadata_kaggle['flux_max'] - test_metadata_kaggle['flux_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_kaggle['flux_std_divided_by_skew'] = train_metadata_kaggle['flux_std'] / train_metadata_kaggle['flux_skew']\n",
    "test_metadata_kaggle['flux_std_divided_by_skew'] = test_metadata_kaggle['flux_std'] / test_metadata_kaggle['flux_skew']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_metadata_kaggle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = temp['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Writing helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(y.unique())\n",
    "\n",
    "# Taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "# https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "# with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "class_weight = {\n",
    "    c: 1 for c in classes\n",
    "}\n",
    "for c in [64, 15]:\n",
    "    class_weight[c] = 2\n",
    "\n",
    "print('Unique classes : ', classes)\n",
    "\n",
    "train_id = temp['object_id']\n",
    "del temp['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights\n",
    "w = y.value_counts()\n",
    "weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "\n",
    "def multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lgb_multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n",
    "\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return 'wloss', loss, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 ) Defining hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=51)\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "lgb_params = {\n",
    "'random_state':51,\n",
    "'device': 'cpu', \n",
    "'objective': 'multiclass', \n",
    "'num_class': 14, \n",
    "'boosting_type': 'gbdt', \n",
    "'n_jobs': -1, \n",
    "'max_depth': 7, \n",
    "'n_estimators': 500, \n",
    "'subsample_freq': 2, \n",
    "'subsample_for_bin': 5000, \n",
    "'min_data_per_group': 100, \n",
    "'max_cat_to_onehot': 4, \n",
    "'cat_l2': 1.0, \n",
    "'cat_smooth': 59.5, \n",
    "'max_cat_threshold': 32, \n",
    "'metric_freq': 10, \n",
    "'verbosity': -1, \n",
    "'metric': 'multi_logloss', \n",
    "'xgboost_dart_mode': False, \n",
    "'uniform_drop': False, \n",
    "'colsample_bytree': 0.5, \n",
    "'drop_rate': 0.173, \n",
    "'learning_rate': 0.0267, \n",
    "'max_drop': 5, \n",
    "'min_child_samples': 10, \n",
    "'min_child_weight': 100.0, \n",
    "'min_split_gain': 0.1, \n",
    "'num_leaves': 7, \n",
    "'reg_alpha': 0.1, \n",
    "'reg_lambda': 0.00023, \n",
    "'skip_drop': 0.44, \n",
    "'subsample': 0.75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights\n",
    "w = y.value_counts()\n",
    "weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "\n",
    "oof_preds = np.zeros((len(temp), np.unique(y).shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    trn_x, trn_y = temp.iloc[trn_], y.iloc[trn_]\n",
    "    val_x, val_y = temp.iloc[val_], y.iloc[val_]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(\n",
    "        trn_x, trn_y,\n",
    "        eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "        eval_metric=lgb_multi_weighted_logloss,\n",
    "        verbose=100,\n",
    "        early_stopping_rounds=50,\n",
    "        sample_weight=trn_y.map(weights)\n",
    "    )\n",
    "    oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "    print(multi_weighted_logloss(val_y, oof_preds[val_, :]))\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = temp.columns\n",
    "    imp_df['gain'] = clf.feature_importances_\n",
    "    imp_df['fold'] = fold_ + 1\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "    clfs.append(clf)\n",
    "\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(y_true=y, y_preds=oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(temp.columns.values)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(test_metadata_kaggle.columns.values)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df.sort_values(by ='gain',ascending=False).reset_index(drop=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12) Preparing test data for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#temp_test = test_metadata_kaggle.merge(right = test_metadata[[x for x in test_metadata.columns if x not in ignored_columns ]] ,how='left',on = 'object_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_test = test_metadata_kaggle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_test['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape,temp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(temp.columns) == list(temp_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()\n",
    "del train_metadata_kaggle,test_metadata_kaggle\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_pred0 = pd.DataFrame()\n",
    "test_pred1 = pd.DataFrame()\n",
    "test_pred2 = pd.DataFrame()\n",
    "test_pred3 = pd.DataFrame()\n",
    "test_pred4 = pd.DataFrame()\n",
    "\n",
    "list_of_df = [test_pred0,test_pred1,test_pred2,test_pred3,test_pred4]\n",
    "\n",
    "for num,c in enumerate(clfs):\n",
    "    print(num)\n",
    "    for k in range(0,len(temp_test),500000):\n",
    "        print(k)\n",
    "        test_pred = pd.DataFrame(c.predict_proba(temp_test[ k:k+500000] ))\n",
    "        list_of_df[num] = pd.concat([list_of_df[num],test_pred],axis=0)\n",
    "        del test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = pd.DataFrame()\n",
    "test_pred2 = (list_of_df[0] + list_of_df[1] + list_of_df[2] + list_of_df[3] + list_of_df[4])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2[14] = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = test_pred2 / 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = test_pred2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_columns = ['object_id','class_6','class_15','class_16','class_42','class_52','class_53','class_62','class_64','class_65','class_67','class_88','class_90','class_92','class_95','class_99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2.columns = temp_columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred2.shape,test_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_id.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id.index == test_pred2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_pred = pd.concat([test_id,test_pred2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred[temp_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_pred.to_csv('test_pred_8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
