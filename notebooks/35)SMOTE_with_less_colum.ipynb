{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import lightgbm as lgb\n",
    "import itertools\n",
    "import pickle, gzip\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "np.warnings.filterwarnings('ignore')\n",
    "import dask.dataframe as dd\n",
    "import missingno as msno\n",
    "from pandasql import sqldf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always seed the randomness of this universe\n",
    "np.random.seed(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 100) (3492890, 99)\n",
      "CPU times: user 2min 24s, sys: 7.97 s, total: 2min 32s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_metadata_kaggle = dd.read_csv('mydata_train_metadata.csv')\n",
    "test_metadata_kaggle = dd.read_csv('mydata_test_metadata.csv')\n",
    "train_metadata_kaggle = train_metadata_kaggle.compute()\n",
    "test_metadata_kaggle = test_metadata_kaggle.compute()\n",
    "print(train_metadata_kaggle.shape,test_metadata_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%time\\nf1_train = dd.read_csv('cesium_train_embeddings.csv')\\nf1_test = dd.read_csv('cesium_test_embeddings.csv')\\nf1_train = f1_train.compute()\\nf1_test = f1_test.compute()\\nprint(f1_train.shape,f1_test.shape)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "f1_train = dd.read_csv('cesium_train_embeddings.csv')\n",
    "f1_test = dd.read_csv('cesium_test_embeddings.csv')\n",
    "f1_train = f1_train.compute()\n",
    "f1_test = f1_test.compute()\n",
    "print(f1_train.shape,f1_test.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%time\\ntrain_metadata_kaggle = train_metadata_kaggle.merge(f1_train,how='left',on = 'object_id')\\ntest_metadata_kaggle = test_metadata_kaggle.merge(f1_test,how='left',on = 'object_id')\\nprint(train_metadata_kaggle.shape,test_metadata_kaggle.shape)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "train_metadata_kaggle = train_metadata_kaggle.merge(f1_train,how='left',on = 'object_id')\n",
    "test_metadata_kaggle = test_metadata_kaggle.merge(f1_test,how='left',on = 'object_id')\n",
    "print(train_metadata_kaggle.shape,test_metadata_kaggle.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%time\\nf2_train = dd.read_csv('myfeatures_train_embeddings.csv')\\nf2_test = dd.read_csv('myfeatures_test_embeddings.csv')\\nf2_train = f2_train.compute()\\nf2_test = f2_test.compute()\\nprint(f2_train.shape,f2_test.shape)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "f2_train = dd.read_csv('myfeatures_train_embeddings.csv')\n",
    "f2_test = dd.read_csv('myfeatures_test_embeddings.csv')\n",
    "f2_train = f2_train.compute()\n",
    "f2_test = f2_test.compute()\n",
    "print(f2_train.shape,f2_test.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%time\\ntrain_metadata_kaggle = train_metadata_kaggle.merge(f2_train,how='left',on = 'object_id')\\ntest_metadata_kaggle = test_metadata_kaggle.merge(f2_test,how='left',on = 'object_id')\\nprint(train_metadata_kaggle.shape,test_metadata_kaggle.shape)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "train_metadata_kaggle = train_metadata_kaggle.merge(f2_train,how='left',on = 'object_id')\n",
    "test_metadata_kaggle = test_metadata_kaggle.merge(f2_test,how='left',on = 'object_id')\n",
    "print(train_metadata_kaggle.shape,test_metadata_kaggle.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_metadata_kaggle['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lgb_multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n",
    "\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return 'wloss', loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%time\\ncesium_drop = ['__flux_percentile_ratio_mid50___5_', '__flux_percentile_ratio_mid65___2_', '__median_absolute_deviation___2_',\\n  '__qso_log_chi2_qsonu___0_', '__stetson_k___1_', '__freq1_signif___2_', '__stetson_k___2_', '__freq3_amplitude1___1_',\\n   '__median_absolute_deviation___2_', '__percent_close_to_median___2_',\\n   '__freq_varrat___5_','__freq_varrat___4_','__qso_log_chi2_qsonu___3_','__qso_log_chi2_qsonu___1_',\\n'__qso_log_chi2_qsonu___5_','__std___4_', '__freq_varrat___3_','__amplitude___2_']\\ncolumns_from_my_data = ['A0_sum_flux', 'A0_mean_flux', 'A0_std_detected', 'A1_mean_detected', 'A2_sum_detected', 'A4_mean_detected',\\n 'A5_std_detected', 'A5_mean_detected', 'percent_p2_region_minus_1', 'A2_min_flux', 'A5_sum_detected']\\ntrain_metadata_kaggle.drop(cesium_drop,inplace=True,axis=1)\\ntest_metadata_kaggle.drop(cesium_drop,inplace=True,axis=1)\\ntrain_metadata_kaggle.drop(columns_from_my_data,inplace=True,axis=1)\\ntest_metadata_kaggle.drop(columns_from_my_data,inplace=True,axis=1)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "cesium_drop = ['__flux_percentile_ratio_mid50___5_', '__flux_percentile_ratio_mid65___2_', '__median_absolute_deviation___2_',\n",
    "  '__qso_log_chi2_qsonu___0_', '__stetson_k___1_', '__freq1_signif___2_', '__stetson_k___2_', '__freq3_amplitude1___1_',\n",
    "   '__median_absolute_deviation___2_', '__percent_close_to_median___2_',\n",
    "   '__freq_varrat___5_','__freq_varrat___4_','__qso_log_chi2_qsonu___3_','__qso_log_chi2_qsonu___1_',\n",
    "'__qso_log_chi2_qsonu___5_','__std___4_', '__freq_varrat___3_','__amplitude___2_']\n",
    "columns_from_my_data = ['A0_sum_flux', 'A0_mean_flux', 'A0_std_detected', 'A1_mean_detected', 'A2_sum_detected', 'A4_mean_detected',\n",
    " 'A5_std_detected', 'A5_mean_detected', 'percent_p2_region_minus_1', 'A2_min_flux', 'A5_sum_detected']\n",
    "train_metadata_kaggle.drop(cesium_drop,inplace=True,axis=1)\n",
    "test_metadata_kaggle.drop(cesium_drop,inplace=True,axis=1)\n",
    "train_metadata_kaggle.drop(columns_from_my_data,inplace=True,axis=1)\n",
    "test_metadata_kaggle.drop(columns_from_my_data,inplace=True,axis=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>flux_min</th>\n",
       "      <th>flux_max</th>\n",
       "      <th>flux_mean</th>\n",
       "      <th>flux_median</th>\n",
       "      <th>flux_std</th>\n",
       "      <th>flux_skew</th>\n",
       "      <th>flux_err_min</th>\n",
       "      <th>flux_err_max</th>\n",
       "      <th>flux_err_mean</th>\n",
       "      <th>flux_err_median</th>\n",
       "      <th>flux_err_std</th>\n",
       "      <th>flux_err_skew</th>\n",
       "      <th>detected_mean</th>\n",
       "      <th>flux_ratio_sq_sum</th>\n",
       "      <th>flux_ratio_sq_skew</th>\n",
       "      <th>flux_by_flux_ratio_sq_sum</th>\n",
       "      <th>flux_by_flux_ratio_sq_skew</th>\n",
       "      <th>flux_w_mean</th>\n",
       "      <th>flux_diff1</th>\n",
       "      <th>flux_diff2</th>\n",
       "      <th>flux_diff3</th>\n",
       "      <th>0__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>0__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>0__kurtosis</th>\n",
       "      <th>0__skewness</th>\n",
       "      <th>1__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>1__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>1__kurtosis</th>\n",
       "      <th>1__skewness</th>\n",
       "      <th>2__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>2__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>2__kurtosis</th>\n",
       "      <th>2__skewness</th>\n",
       "      <th>3__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>3__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>3__kurtosis</th>\n",
       "      <th>3__skewness</th>\n",
       "      <th>4__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>4__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>4__kurtosis</th>\n",
       "      <th>4__skewness</th>\n",
       "      <th>5__fft_coefficient__coeff_0__attr_\"abs\"</th>\n",
       "      <th>5__fft_coefficient__coeff_1__attr_\"abs\"</th>\n",
       "      <th>5__kurtosis</th>\n",
       "      <th>5__skewness</th>\n",
       "      <th>flux__length</th>\n",
       "      <th>flux__longest_strike_above_mean</th>\n",
       "      <th>flux__longest_strike_below_mean</th>\n",
       "      <th>flux__mean_abs_change</th>\n",
       "      <th>flux__mean_change</th>\n",
       "      <th>flux_by_flux_ratio_sq__longest_strike_above_mean</th>\n",
       "      <th>flux_by_flux_ratio_sq__longest_strike_below_mean</th>\n",
       "      <th>mjd__mean_abs_change</th>\n",
       "      <th>mjd__mean_change</th>\n",
       "      <th>mjd_diff_det</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>mwebv</th>\n",
       "      <th>target</th>\n",
       "      <th>haversine</th>\n",
       "      <th>latlon1</th>\n",
       "      <th>hostgal_photoz_certain</th>\n",
       "      <th>A0_sum_flux</th>\n",
       "      <th>A0_mean_flux</th>\n",
       "      <th>A0_std_detected</th>\n",
       "      <th>A1_mean_detected</th>\n",
       "      <th>A2_sum_detected</th>\n",
       "      <th>A4_mean_detected</th>\n",
       "      <th>A5_std_detected</th>\n",
       "      <th>A5_mean_detected</th>\n",
       "      <th>percent_p2_region_minus_1</th>\n",
       "      <th>A2_min_flux</th>\n",
       "      <th>A5_sum_detected</th>\n",
       "      <th>__flux_percentile_ratio_mid50___5_</th>\n",
       "      <th>__flux_percentile_ratio_mid65___2_</th>\n",
       "      <th>__median_absolute_deviation___2_</th>\n",
       "      <th>__qso_log_chi2_qsonu___0_</th>\n",
       "      <th>__stetson_k___1_</th>\n",
       "      <th>__freq1_signif___2_</th>\n",
       "      <th>__stetson_k___2_</th>\n",
       "      <th>__freq3_amplitude1___1_</th>\n",
       "      <th>__median_absolute_deviation___2_.1</th>\n",
       "      <th>__percent_close_to_median___2_</th>\n",
       "      <th>__freq_varrat___5_</th>\n",
       "      <th>__freq_varrat___4_</th>\n",
       "      <th>__qso_log_chi2_qsonu___3_</th>\n",
       "      <th>__qso_log_chi2_qsonu___1_</th>\n",
       "      <th>__qso_log_chi2_qsonu___5_</th>\n",
       "      <th>__std___4_</th>\n",
       "      <th>__freq_varrat___3_</th>\n",
       "      <th>__amplitude___2_</th>\n",
       "      <th>outlierScore</th>\n",
       "      <th>hipd</th>\n",
       "      <th>lipd</th>\n",
       "      <th>highEnergy_transitory_1.0_TF</th>\n",
       "      <th>highEnergy_transitory_1.5_TF</th>\n",
       "      <th>lowEnergy_transitory_1.0_TF</th>\n",
       "      <th>lowEnergy_transitory_1.5_TF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615</td>\n",
       "      <td>-1100.440063</td>\n",
       "      <td>660.626343</td>\n",
       "      <td>-123.096998</td>\n",
       "      <td>-89.477524</td>\n",
       "      <td>394.109851</td>\n",
       "      <td>-0.349540</td>\n",
       "      <td>2.130510</td>\n",
       "      <td>12.845472</td>\n",
       "      <td>4.482743</td>\n",
       "      <td>3.835269</td>\n",
       "      <td>1.744747</td>\n",
       "      <td>1.623740</td>\n",
       "      <td>0.946023</td>\n",
       "      <td>2.929669e+06</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>-9.601766e+08</td>\n",
       "      <td>-1.414322</td>\n",
       "      <td>-327.742307</td>\n",
       "      <td>1761.066406</td>\n",
       "      <td>-14.306331</td>\n",
       "      <td>-5.373326</td>\n",
       "      <td>205.036926</td>\n",
       "      <td>1628.427737</td>\n",
       "      <td>-1.475181</td>\n",
       "      <td>0.128917</td>\n",
       "      <td>22370.594834</td>\n",
       "      <td>2806.374162</td>\n",
       "      <td>-1.255123</td>\n",
       "      <td>0.415580</td>\n",
       "      <td>7780.500807</td>\n",
       "      <td>2805.598113</td>\n",
       "      <td>-1.409885</td>\n",
       "      <td>0.339918</td>\n",
       "      <td>7024.003068</td>\n",
       "      <td>2536.068846</td>\n",
       "      <td>-1.449858</td>\n",
       "      <td>0.293128</td>\n",
       "      <td>3245.366349</td>\n",
       "      <td>2741.539785</td>\n",
       "      <td>-1.548319</td>\n",
       "      <td>0.200096</td>\n",
       "      <td>2704.641265</td>\n",
       "      <td>2893.344217</td>\n",
       "      <td>-1.592820</td>\n",
       "      <td>0.125268</td>\n",
       "      <td>352.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>202.114067</td>\n",
       "      <td>1.999688</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.631898</td>\n",
       "      <td>2.631898</td>\n",
       "      <td>873.7903</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017</td>\n",
       "      <td>92</td>\n",
       "      <td>0.319006</td>\n",
       "      <td>-1.528827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-205.03693</td>\n",
       "      <td>-3.254554</td>\n",
       "      <td>0.3528</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>57</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.2854</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-682.000</td>\n",
       "      <td>52</td>\n",
       "      <td>5.562230e-26</td>\n",
       "      <td>6.719410e-20</td>\n",
       "      <td>368.12900</td>\n",
       "      <td>6.217890</td>\n",
       "      <td>1.091730</td>\n",
       "      <td>5.49891</td>\n",
       "      <td>1.053490</td>\n",
       "      <td>114.465000</td>\n",
       "      <td>368.12900</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.401664</td>\n",
       "      <td>0.129578</td>\n",
       "      <td>9.16612</td>\n",
       "      <td>9.508750</td>\n",
       "      <td>7.344980</td>\n",
       "      <td>289.27700</td>\n",
       "      <td>0.110785</td>\n",
       "      <td>646.9220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>713</td>\n",
       "      <td>-14.735178</td>\n",
       "      <td>14.770886</td>\n",
       "      <td>-1.423351</td>\n",
       "      <td>-0.873033</td>\n",
       "      <td>6.471144</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.639458</td>\n",
       "      <td>9.115748</td>\n",
       "      <td>2.359620</td>\n",
       "      <td>1.998217</td>\n",
       "      <td>1.509888</td>\n",
       "      <td>1.633246</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>5.886068e+03</td>\n",
       "      <td>3.439423</td>\n",
       "      <td>-2.875087e+04</td>\n",
       "      <td>-3.454554</td>\n",
       "      <td>-4.884564</td>\n",
       "      <td>29.506064</td>\n",
       "      <td>-20.730002</td>\n",
       "      <td>-6.040676</td>\n",
       "      <td>190.427851</td>\n",
       "      <td>299.586559</td>\n",
       "      <td>-1.014003</td>\n",
       "      <td>0.260052</td>\n",
       "      <td>57.109047</td>\n",
       "      <td>192.539229</td>\n",
       "      <td>-1.097170</td>\n",
       "      <td>-0.087865</td>\n",
       "      <td>44.477327</td>\n",
       "      <td>191.057528</td>\n",
       "      <td>-1.188472</td>\n",
       "      <td>-0.022678</td>\n",
       "      <td>55.270113</td>\n",
       "      <td>212.522263</td>\n",
       "      <td>-1.142896</td>\n",
       "      <td>-0.167176</td>\n",
       "      <td>50.414646</td>\n",
       "      <td>203.892482</td>\n",
       "      <td>-1.190245</td>\n",
       "      <td>-0.064134</td>\n",
       "      <td>100.473776</td>\n",
       "      <td>143.963093</td>\n",
       "      <td>-0.797047</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>350.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.935177</td>\n",
       "      <td>-0.050944</td>\n",
       "      <td>199.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.352571</td>\n",
       "      <td>14.352571</td>\n",
       "      <td>846.8017</td>\n",
       "      <td>1.6267</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>45.4063</td>\n",
       "      <td>0.007</td>\n",
       "      <td>88</td>\n",
       "      <td>1.698939</td>\n",
       "      <td>3.258921</td>\n",
       "      <td>2.099614</td>\n",
       "      <td>-190.42786</td>\n",
       "      <td>-2.720398</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-10.070</td>\n",
       "      <td>0</td>\n",
       "      <td>2.119070e-02</td>\n",
       "      <td>8.243180e-02</td>\n",
       "      <td>5.10035</td>\n",
       "      <td>2.187190</td>\n",
       "      <td>1.066100</td>\n",
       "      <td>3.95669</td>\n",
       "      <td>1.088180</td>\n",
       "      <td>0.851103</td>\n",
       "      <td>5.10035</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.369518</td>\n",
       "      <td>0.166179</td>\n",
       "      <td>2.79753</td>\n",
       "      <td>3.124810</td>\n",
       "      <td>0.659762</td>\n",
       "      <td>6.34953</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>10.2985</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.909016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>-19.159811</td>\n",
       "      <td>47.310059</td>\n",
       "      <td>2.267434</td>\n",
       "      <td>0.409172</td>\n",
       "      <td>8.022239</td>\n",
       "      <td>3.177854</td>\n",
       "      <td>0.695106</td>\n",
       "      <td>11.281384</td>\n",
       "      <td>2.471061</td>\n",
       "      <td>1.990851</td>\n",
       "      <td>1.721134</td>\n",
       "      <td>1.823726</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>4.124452e+03</td>\n",
       "      <td>5.480405</td>\n",
       "      <td>1.046502e+05</td>\n",
       "      <td>5.989138</td>\n",
       "      <td>25.373110</td>\n",
       "      <td>66.469870</td>\n",
       "      <td>29.315018</td>\n",
       "      <td>2.619697</td>\n",
       "      <td>3.461790</td>\n",
       "      <td>4.729538</td>\n",
       "      <td>0.474215</td>\n",
       "      <td>0.356910</td>\n",
       "      <td>7.334944</td>\n",
       "      <td>13.515895</td>\n",
       "      <td>0.976374</td>\n",
       "      <td>0.471342</td>\n",
       "      <td>124.845250</td>\n",
       "      <td>119.500254</td>\n",
       "      <td>5.131290</td>\n",
       "      <td>2.385066</td>\n",
       "      <td>168.280524</td>\n",
       "      <td>162.799417</td>\n",
       "      <td>7.125665</td>\n",
       "      <td>2.662075</td>\n",
       "      <td>219.745132</td>\n",
       "      <td>202.532898</td>\n",
       "      <td>6.081065</td>\n",
       "      <td>2.537802</td>\n",
       "      <td>231.509177</td>\n",
       "      <td>199.286370</td>\n",
       "      <td>3.583130</td>\n",
       "      <td>1.680352</td>\n",
       "      <td>330.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.227614</td>\n",
       "      <td>-0.008131</td>\n",
       "      <td>4.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>3.580623</td>\n",
       "      <td>3.580623</td>\n",
       "      <td>78.7737</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>40.2561</td>\n",
       "      <td>0.021</td>\n",
       "      <td>42</td>\n",
       "      <td>1.818030</td>\n",
       "      <td>3.128522</td>\n",
       "      <td>0.229779</td>\n",
       "      <td>-3.46179</td>\n",
       "      <td>-0.048080</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.769</td>\n",
       "      <td>-2.850</td>\n",
       "      <td>4</td>\n",
       "      <td>1.942280e-04</td>\n",
       "      <td>5.511800e-01</td>\n",
       "      <td>1.04253</td>\n",
       "      <td>-0.307228</td>\n",
       "      <td>0.933091</td>\n",
       "      <td>4.61663</td>\n",
       "      <td>0.634723</td>\n",
       "      <td>0.454918</td>\n",
       "      <td>1.04253</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.500549</td>\n",
       "      <td>0.318256</td>\n",
       "      <td>3.04833</td>\n",
       "      <td>0.127758</td>\n",
       "      <td>1.669430</td>\n",
       "      <td>10.60480</td>\n",
       "      <td>0.292954</td>\n",
       "      <td>11.9218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745</td>\n",
       "      <td>-15.494463</td>\n",
       "      <td>220.795212</td>\n",
       "      <td>8.909206</td>\n",
       "      <td>1.035895</td>\n",
       "      <td>27.558208</td>\n",
       "      <td>4.979826</td>\n",
       "      <td>0.567170</td>\n",
       "      <td>55.892746</td>\n",
       "      <td>2.555576</td>\n",
       "      <td>1.819875</td>\n",
       "      <td>3.537324</td>\n",
       "      <td>10.741655</td>\n",
       "      <td>0.173789</td>\n",
       "      <td>9.416165e+04</td>\n",
       "      <td>9.611274</td>\n",
       "      <td>1.439125e+07</td>\n",
       "      <td>11.141069</td>\n",
       "      <td>152.835617</td>\n",
       "      <td>236.289675</td>\n",
       "      <td>26.521968</td>\n",
       "      <td>1.546038</td>\n",
       "      <td>129.421659</td>\n",
       "      <td>123.298327</td>\n",
       "      <td>4.629801</td>\n",
       "      <td>2.023211</td>\n",
       "      <td>320.174052</td>\n",
       "      <td>280.440312</td>\n",
       "      <td>50.868880</td>\n",
       "      <td>7.007099</td>\n",
       "      <td>543.845781</td>\n",
       "      <td>491.548270</td>\n",
       "      <td>36.088137</td>\n",
       "      <td>5.688194</td>\n",
       "      <td>807.123762</td>\n",
       "      <td>710.721942</td>\n",
       "      <td>16.392533</td>\n",
       "      <td>3.751603</td>\n",
       "      <td>735.528417</td>\n",
       "      <td>680.055280</td>\n",
       "      <td>13.747434</td>\n",
       "      <td>3.476420</td>\n",
       "      <td>591.037583</td>\n",
       "      <td>523.503586</td>\n",
       "      <td>12.134629</td>\n",
       "      <td>3.170857</td>\n",
       "      <td>351.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>7.065548</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>2.061453</td>\n",
       "      <td>2.061453</td>\n",
       "      <td>123.6872</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>40.7951</td>\n",
       "      <td>0.007</td>\n",
       "      <td>90</td>\n",
       "      <td>0.495223</td>\n",
       "      <td>6.893743</td>\n",
       "      <td>0.890445</td>\n",
       "      <td>129.42166</td>\n",
       "      <td>1.797523</td>\n",
       "      <td>0.1655</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.768</td>\n",
       "      <td>-2.160</td>\n",
       "      <td>7</td>\n",
       "      <td>8.401600e-03</td>\n",
       "      <td>5.463690e-01</td>\n",
       "      <td>1.41645</td>\n",
       "      <td>1.432200</td>\n",
       "      <td>0.295163</td>\n",
       "      <td>3.96789</td>\n",
       "      <td>0.394683</td>\n",
       "      <td>3.595670</td>\n",
       "      <td>1.41645</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.489589</td>\n",
       "      <td>0.360868</td>\n",
       "      <td>6.06886</td>\n",
       "      <td>5.840820</td>\n",
       "      <td>2.820440</td>\n",
       "      <td>32.77250</td>\n",
       "      <td>0.290652</td>\n",
       "      <td>111.4770</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124</td>\n",
       "      <td>-16.543753</td>\n",
       "      <td>143.600189</td>\n",
       "      <td>7.145702</td>\n",
       "      <td>1.141288</td>\n",
       "      <td>20.051722</td>\n",
       "      <td>4.406298</td>\n",
       "      <td>0.695277</td>\n",
       "      <td>11.383690</td>\n",
       "      <td>2.753004</td>\n",
       "      <td>2.214854</td>\n",
       "      <td>1.933837</td>\n",
       "      <td>1.794938</td>\n",
       "      <td>0.173295</td>\n",
       "      <td>3.432418e+04</td>\n",
       "      <td>7.868462</td>\n",
       "      <td>3.015599e+06</td>\n",
       "      <td>7.908174</td>\n",
       "      <td>87.856390</td>\n",
       "      <td>160.143942</td>\n",
       "      <td>22.411225</td>\n",
       "      <td>1.822792</td>\n",
       "      <td>41.639721</td>\n",
       "      <td>32.987125</td>\n",
       "      <td>0.822496</td>\n",
       "      <td>-0.332169</td>\n",
       "      <td>268.808929</td>\n",
       "      <td>207.812015</td>\n",
       "      <td>6.112295</td>\n",
       "      <td>2.377222</td>\n",
       "      <td>594.150153</td>\n",
       "      <td>498.509820</td>\n",
       "      <td>10.343254</td>\n",
       "      <td>3.075437</td>\n",
       "      <td>643.020183</td>\n",
       "      <td>555.512641</td>\n",
       "      <td>14.095862</td>\n",
       "      <td>3.603208</td>\n",
       "      <td>574.553907</td>\n",
       "      <td>524.107264</td>\n",
       "      <td>16.377058</td>\n",
       "      <td>3.904008</td>\n",
       "      <td>393.114268</td>\n",
       "      <td>357.907185</td>\n",
       "      <td>14.434470</td>\n",
       "      <td>3.657305</td>\n",
       "      <td>352.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>6.727352</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>10.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>2.231855</td>\n",
       "      <td>2.231855</td>\n",
       "      <td>133.9113</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>40.4166</td>\n",
       "      <td>0.024</td>\n",
       "      <td>90</td>\n",
       "      <td>0.395162</td>\n",
       "      <td>-1.928064</td>\n",
       "      <td>0.245788</td>\n",
       "      <td>41.63972</td>\n",
       "      <td>0.660948</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.707</td>\n",
       "      <td>-2.084</td>\n",
       "      <td>4</td>\n",
       "      <td>2.702260e-02</td>\n",
       "      <td>6.018110e-01</td>\n",
       "      <td>1.33779</td>\n",
       "      <td>-0.064359</td>\n",
       "      <td>0.674119</td>\n",
       "      <td>5.24444</td>\n",
       "      <td>0.560453</td>\n",
       "      <td>1.205580</td>\n",
       "      <td>1.33779</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.673592</td>\n",
       "      <td>0.382847</td>\n",
       "      <td>5.07231</td>\n",
       "      <td>3.407900</td>\n",
       "      <td>2.312920</td>\n",
       "      <td>26.63330</td>\n",
       "      <td>0.250639</td>\n",
       "      <td>54.3781</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id     flux_min    flux_max   flux_mean  flux_median    flux_std  \\\n",
       "0        615 -1100.440063  660.626343 -123.096998   -89.477524  394.109851   \n",
       "1        713   -14.735178   14.770886   -1.423351    -0.873033    6.471144   \n",
       "2        730   -19.159811   47.310059    2.267434     0.409172    8.022239   \n",
       "3        745   -15.494463  220.795212    8.909206     1.035895   27.558208   \n",
       "4       1124   -16.543753  143.600189    7.145702     1.141288   20.051722   \n",
       "\n",
       "   flux_skew  flux_err_min  flux_err_max  flux_err_mean  flux_err_median  \\\n",
       "0  -0.349540      2.130510     12.845472       4.482743         3.835269   \n",
       "1   0.014989      0.639458      9.115748       2.359620         1.998217   \n",
       "2   3.177854      0.695106     11.281384       2.471061         1.990851   \n",
       "3   4.979826      0.567170     55.892746       2.555576         1.819875   \n",
       "4   4.406298      0.695277     11.383690       2.753004         2.214854   \n",
       "\n",
       "   flux_err_std  flux_err_skew  detected_mean  flux_ratio_sq_sum  \\\n",
       "0      1.744747       1.623740       0.946023       2.929669e+06   \n",
       "1      1.509888       1.633246       0.171429       5.886068e+03   \n",
       "2      1.721134       1.823726       0.069697       4.124452e+03   \n",
       "3      3.537324      10.741655       0.173789       9.416165e+04   \n",
       "4      1.933837       1.794938       0.173295       3.432418e+04   \n",
       "\n",
       "   flux_ratio_sq_skew  flux_by_flux_ratio_sq_sum  flux_by_flux_ratio_sq_skew  \\\n",
       "0            0.812722              -9.601766e+08                   -1.414322   \n",
       "1            3.439423              -2.875087e+04                   -3.454554   \n",
       "2            5.480405               1.046502e+05                    5.989138   \n",
       "3            9.611274               1.439125e+07                   11.141069   \n",
       "4            7.868462               3.015599e+06                    7.908174   \n",
       "\n",
       "   flux_w_mean   flux_diff1  flux_diff2  flux_diff3  \\\n",
       "0  -327.742307  1761.066406  -14.306331   -5.373326   \n",
       "1    -4.884564    29.506064  -20.730002   -6.040676   \n",
       "2    25.373110    66.469870   29.315018    2.619697   \n",
       "3   152.835617   236.289675   26.521968    1.546038   \n",
       "4    87.856390   160.143942   22.411225    1.822792   \n",
       "\n",
       "   0__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                               205.036926   \n",
       "1                               190.427851   \n",
       "2                                 3.461790   \n",
       "3                               129.421659   \n",
       "4                                41.639721   \n",
       "\n",
       "   0__fft_coefficient__coeff_1__attr_\"abs\"  0__kurtosis  0__skewness  \\\n",
       "0                              1628.427737    -1.475181     0.128917   \n",
       "1                               299.586559    -1.014003     0.260052   \n",
       "2                                 4.729538     0.474215     0.356910   \n",
       "3                               123.298327     4.629801     2.023211   \n",
       "4                                32.987125     0.822496    -0.332169   \n",
       "\n",
       "   1__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                             22370.594834   \n",
       "1                                57.109047   \n",
       "2                                 7.334944   \n",
       "3                               320.174052   \n",
       "4                               268.808929   \n",
       "\n",
       "   1__fft_coefficient__coeff_1__attr_\"abs\"  1__kurtosis  1__skewness  \\\n",
       "0                              2806.374162    -1.255123     0.415580   \n",
       "1                               192.539229    -1.097170    -0.087865   \n",
       "2                                13.515895     0.976374     0.471342   \n",
       "3                               280.440312    50.868880     7.007099   \n",
       "4                               207.812015     6.112295     2.377222   \n",
       "\n",
       "   2__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                              7780.500807   \n",
       "1                                44.477327   \n",
       "2                               124.845250   \n",
       "3                               543.845781   \n",
       "4                               594.150153   \n",
       "\n",
       "   2__fft_coefficient__coeff_1__attr_\"abs\"  2__kurtosis  2__skewness  \\\n",
       "0                              2805.598113    -1.409885     0.339918   \n",
       "1                               191.057528    -1.188472    -0.022678   \n",
       "2                               119.500254     5.131290     2.385066   \n",
       "3                               491.548270    36.088137     5.688194   \n",
       "4                               498.509820    10.343254     3.075437   \n",
       "\n",
       "   3__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                              7024.003068   \n",
       "1                                55.270113   \n",
       "2                               168.280524   \n",
       "3                               807.123762   \n",
       "4                               643.020183   \n",
       "\n",
       "   3__fft_coefficient__coeff_1__attr_\"abs\"  3__kurtosis  3__skewness  \\\n",
       "0                              2536.068846    -1.449858     0.293128   \n",
       "1                               212.522263    -1.142896    -0.167176   \n",
       "2                               162.799417     7.125665     2.662075   \n",
       "3                               710.721942    16.392533     3.751603   \n",
       "4                               555.512641    14.095862     3.603208   \n",
       "\n",
       "   4__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                              3245.366349   \n",
       "1                                50.414646   \n",
       "2                               219.745132   \n",
       "3                               735.528417   \n",
       "4                               574.553907   \n",
       "\n",
       "   4__fft_coefficient__coeff_1__attr_\"abs\"  4__kurtosis  4__skewness  \\\n",
       "0                              2741.539785    -1.548319     0.200096   \n",
       "1                               203.892482    -1.190245    -0.064134   \n",
       "2                               202.532898     6.081065     2.537802   \n",
       "3                               680.055280    13.747434     3.476420   \n",
       "4                               524.107264    16.377058     3.904008   \n",
       "\n",
       "   5__fft_coefficient__coeff_0__attr_\"abs\"  \\\n",
       "0                              2704.641265   \n",
       "1                               100.473776   \n",
       "2                               231.509177   \n",
       "3                               591.037583   \n",
       "4                               393.114268   \n",
       "\n",
       "   5__fft_coefficient__coeff_1__attr_\"abs\"  5__kurtosis  5__skewness  \\\n",
       "0                              2893.344217    -1.592820     0.125268   \n",
       "1                               143.963093    -0.797047     0.218182   \n",
       "2                               199.286370     3.583130     1.680352   \n",
       "3                               523.503586    12.134629     3.170857   \n",
       "4                               357.907185    14.434470     3.657305   \n",
       "\n",
       "   flux__length  flux__longest_strike_above_mean  \\\n",
       "0         352.0                             19.0   \n",
       "1         350.0                             50.0   \n",
       "2         330.0                             13.0   \n",
       "3         351.0                             19.0   \n",
       "4         352.0                             19.0   \n",
       "\n",
       "   flux__longest_strike_below_mean  flux__mean_abs_change  flux__mean_change  \\\n",
       "0                             29.0             202.114067           1.999688   \n",
       "1                             73.0               2.935177          -0.050944   \n",
       "2                             32.0               4.227614          -0.008131   \n",
       "3                            115.0               7.065548           0.008044   \n",
       "4                            158.0               6.727352           0.012543   \n",
       "\n",
       "   flux_by_flux_ratio_sq__longest_strike_above_mean  \\\n",
       "0                                              35.0   \n",
       "1                                             199.0   \n",
       "2                                               4.0   \n",
       "3                                               4.0   \n",
       "4                                              10.0   \n",
       "\n",
       "   flux_by_flux_ratio_sq__longest_strike_below_mean  mjd__mean_abs_change  \\\n",
       "0                                               4.0              2.631898   \n",
       "1                                               8.0             14.352571   \n",
       "2                                             222.0              3.580623   \n",
       "3                                             201.0              2.061453   \n",
       "4                                             231.0              2.231855   \n",
       "\n",
       "   mjd__mean_change  mjd_diff_det  hostgal_photoz  hostgal_photoz_err  \\\n",
       "0          2.631898      873.7903          0.0000              0.0000   \n",
       "1         14.352571      846.8017          1.6267              0.2552   \n",
       "2          3.580623       78.7737          0.2262              0.0157   \n",
       "3          2.061453      123.6872          0.2813              1.1523   \n",
       "4          2.231855      133.9113          0.2415              0.0176   \n",
       "\n",
       "   distmod  mwebv  target  haversine   latlon1  hostgal_photoz_certain  \\\n",
       "0      NaN  0.017      92   0.319006 -1.528827                0.000000   \n",
       "1  45.4063  0.007      88   1.698939  3.258921                2.099614   \n",
       "2  40.2561  0.021      42   1.818030  3.128522                0.229779   \n",
       "3  40.7951  0.007      90   0.495223  6.893743                0.890445   \n",
       "4  40.4166  0.024      90   0.395162 -1.928064                0.245788   \n",
       "\n",
       "   A0_sum_flux  A0_mean_flux  A0_std_detected  A1_mean_detected  \\\n",
       "0   -205.03693     -3.254554           0.3528            0.9653   \n",
       "1   -190.42786     -2.720398           0.3525            0.2678   \n",
       "2     -3.46179     -0.048080           0.0000            0.0000   \n",
       "3    129.42166      1.797523           0.1655            0.1250   \n",
       "4     41.63972      0.660948           0.0000            0.2241   \n",
       "\n",
       "   A2_sum_detected  A4_mean_detected  A5_std_detected  A5_mean_detected  \\\n",
       "0               57            0.9830           0.2854            0.9120   \n",
       "1               15            0.0893           0.0000            0.0000   \n",
       "2                7            0.0980           0.2715            0.0784   \n",
       "3               16            0.2322           0.3364            0.1273   \n",
       "4               18            0.1724           0.2578            0.0702   \n",
       "\n",
       "   percent_p2_region_minus_1  A2_min_flux  A5_sum_detected  \\\n",
       "0                      0.362     -682.000               52   \n",
       "1                      0.250      -10.070                0   \n",
       "2                      0.769       -2.850                4   \n",
       "3                      0.768       -2.160                7   \n",
       "4                      0.707       -2.084                4   \n",
       "\n",
       "   __flux_percentile_ratio_mid50___5_  __flux_percentile_ratio_mid65___2_  \\\n",
       "0                        5.562230e-26                        6.719410e-20   \n",
       "1                        2.119070e-02                        8.243180e-02   \n",
       "2                        1.942280e-04                        5.511800e-01   \n",
       "3                        8.401600e-03                        5.463690e-01   \n",
       "4                        2.702260e-02                        6.018110e-01   \n",
       "\n",
       "   __median_absolute_deviation___2_  __qso_log_chi2_qsonu___0_  \\\n",
       "0                         368.12900                   6.217890   \n",
       "1                           5.10035                   2.187190   \n",
       "2                           1.04253                  -0.307228   \n",
       "3                           1.41645                   1.432200   \n",
       "4                           1.33779                  -0.064359   \n",
       "\n",
       "   __stetson_k___1_  __freq1_signif___2_  __stetson_k___2_  \\\n",
       "0          1.091730              5.49891          1.053490   \n",
       "1          1.066100              3.95669          1.088180   \n",
       "2          0.933091              4.61663          0.634723   \n",
       "3          0.295163              3.96789          0.394683   \n",
       "4          0.674119              5.24444          0.560453   \n",
       "\n",
       "   __freq3_amplitude1___1_  __median_absolute_deviation___2_.1  \\\n",
       "0               114.465000                           368.12900   \n",
       "1                 0.851103                             5.10035   \n",
       "2                 0.454918                             1.04253   \n",
       "3                 3.595670                             1.41645   \n",
       "4                 1.205580                             1.33779   \n",
       "\n",
       "   __percent_close_to_median___2_  __freq_varrat___5_  __freq_varrat___4_  \\\n",
       "0                        0.172414            0.401664            0.129578   \n",
       "1                        0.178571            0.369518            0.166179   \n",
       "2                        0.769231            0.500549            0.318256   \n",
       "3                        0.892857            0.489589            0.360868   \n",
       "4                        0.741379            0.673592            0.382847   \n",
       "\n",
       "   __qso_log_chi2_qsonu___3_  __qso_log_chi2_qsonu___1_  \\\n",
       "0                    9.16612                   9.508750   \n",
       "1                    2.79753                   3.124810   \n",
       "2                    3.04833                   0.127758   \n",
       "3                    6.06886                   5.840820   \n",
       "4                    5.07231                   3.407900   \n",
       "\n",
       "   __qso_log_chi2_qsonu___5_  __std___4_  __freq_varrat___3_  \\\n",
       "0                   7.344980   289.27700            0.110785   \n",
       "1                   0.659762     6.34953            0.111883   \n",
       "2                   1.669430    10.60480            0.292954   \n",
       "3                   2.820440    32.77250            0.290652   \n",
       "4                   2.312920    26.63330            0.250639   \n",
       "\n",
       "   __amplitude___2_  outlierScore      hipd  lipd  \\\n",
       "0          646.9220         0.000  1.000000   1.0   \n",
       "1           10.2985         0.875  1.909016   2.0   \n",
       "2           11.9218         0.000  1.000000   1.0   \n",
       "3          111.4770         0.000  1.000000   1.0   \n",
       "4           54.3781         0.375  1.000000   1.0   \n",
       "\n",
       "   highEnergy_transitory_1.0_TF  highEnergy_transitory_1.5_TF  \\\n",
       "0                             0                             0   \n",
       "1                             1                             0   \n",
       "2                             0                             0   \n",
       "3                             0                             0   \n",
       "4                             0                             0   \n",
       "\n",
       "   lowEnergy_transitory_1.0_TF  lowEnergy_transitory_1.5_TF  \n",
       "0                            0                            0  \n",
       "1                            1                            1  \n",
       "2                            0                            0  \n",
       "3                            0                            0  \n",
       "4                            1                            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6275658544463559\n",
      "1 0.5990572385367394\n",
      "2 0.6562404553921372\n",
      "3 0.6097834282043219\n",
      "4 0.6101227441786252\n",
      "MULTI WEIGHTED LOG LOSS : 0.62060 \n",
      "CPU times: user 8min 36s, sys: 1.28 s, total: 8min 38s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_dict = {}\n",
    "\n",
    "loss_list = []\n",
    "temp = train_metadata_kaggle.copy()\n",
    "#temp = temp.merge(train_metadata[['object_id',column_]],on = 'object_id',how = 'left')\n",
    "y = temp['target']\n",
    "del temp['target']\n",
    "classes = sorted(y.unique())\n",
    "\n",
    "# Taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "# https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "# with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "class_weight = {\n",
    "    c: 1 for c in classes\n",
    "}\n",
    "for c in [64, 15]:\n",
    "    class_weight[c] = 2\n",
    "\n",
    "#print('Unique classes : ', classes)\n",
    "\n",
    "train_id = temp['object_id']\n",
    "del temp['object_id']\n",
    "# Compute weights\n",
    "w = y.value_counts()\n",
    "weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=51)\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "lgb_params = {\n",
    "'random_state':51,\n",
    "'device': 'cpu', \n",
    "'objective': 'multiclass', \n",
    "'num_class': 14, \n",
    "'boosting_type': 'gbdt', \n",
    "'n_jobs': -1, \n",
    "'max_depth': 7, \n",
    "'n_estimators': 1000, \n",
    "'subsample_freq': 2, \n",
    "'subsample_for_bin': 5000, \n",
    "'min_data_per_group': 100, \n",
    "'max_cat_to_onehot': 4, \n",
    "'cat_l2': 1.0, \n",
    "'cat_smooth': 59.5, \n",
    "'max_cat_threshold': 32, \n",
    "'metric_freq': 10, \n",
    "'verbosity': -1, \n",
    "'metric': 'multi_logloss', \n",
    "'xgboost_dart_mode': False, \n",
    "'uniform_drop': False, \n",
    "'colsample_bytree': 0.5, \n",
    "'drop_rate': 0.173, \n",
    "'learning_rate': 0.0267, \n",
    "'max_drop': 5, \n",
    "'min_child_samples': 10,\n",
    "'min_child_weight': 200.0, \n",
    "#'min_child_weight': 100.0, \n",
    "'min_split_gain': 0.1, \n",
    "'num_leaves': 7, \n",
    "#'reg_alpha': 0.1,\n",
    "'reg_alpha': 0.0, \n",
    "'reg_lambda': 0.00023, \n",
    "'skip_drop': 0.44, \n",
    "'subsample': 0.75}\n",
    "oof_preds = np.zeros((len(temp), np.unique(y).shape[0]))\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    trn_x, trn_y = temp.iloc[trn_], y.iloc[trn_]\n",
    "    val_x, val_y = temp.iloc[val_], y.iloc[val_]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(\n",
    "        trn_x, trn_y,\n",
    "        eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "        eval_metric=lgb_multi_weighted_logloss,\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=50,\n",
    "        sample_weight=trn_y.map(weights)\n",
    "    )\n",
    "    oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "    loss_oof = multi_weighted_logloss(val_y, oof_preds[val_, :])\n",
    "    #loss_list.append(loss_oof)\n",
    "    print(fold_,loss_oof)\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = temp.columns\n",
    "    imp_df['gain'] = clf.feature_importances_\n",
    "    imp_df['fold'] = fold_ + 1\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "    clfs.append(clf)\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(y_true=y, y_preds=oof_preds))\n",
    "#final_dict[column_] = loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify to work with kfold\n",
    "#def smoteAdataset(Xig, yig, test_size=0.2, random_state=0):\n",
    "def smoteAdataset(Xig_train, yig_train, Xig_test, yig_test):\n",
    "    \n",
    "        \n",
    "    sm=SMOTE(random_state=51)\n",
    "    Xig_train_res, yig_train_res = sm.fit_sample(Xig_train, yig_train.ravel())\n",
    "\n",
    "        \n",
    "    return Xig_train_res, pd.Series(yig_train_res), Xig_test, pd.Series(yig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25900, 98) (25900,) (1574, 98) (1574,)\n",
      "0 0.5773895028501574\n",
      "(25900, 98) (25900,) (1572, 98) (1572,)\n",
      "1 0.6010813522091171\n",
      "(25900, 98) (25900,) (1571, 98) (1571,)\n",
      "2 0.6550692442902669\n",
      "(25914, 98) (25914,) (1567, 98) (1567,)\n",
      "3 0.5967314617978657\n",
      "(25914, 98) (25914,) (1564, 98) (1564,)\n",
      "4 0.6124223750584648\n",
      "MULTI WEIGHTED LOG LOSS : 0.60843 \n",
      "CPU times: user 22min 31s, sys: 1.74 s, total: 22min 33s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_dict = {}\n",
    "\n",
    "loss_list = []\n",
    "temp = train_metadata_kaggle.copy()\n",
    "temp.fillna(0, inplace=True)\n",
    "#temp = temp.merge(train_metadata[['object_id',column_]],on = 'object_id',how = 'left')\n",
    "y = temp['target']\n",
    "del temp['target']\n",
    "classes = sorted(y.unique())\n",
    "\n",
    "# Taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "# https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "# with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "class_weight = {\n",
    "    c: 1 for c in classes\n",
    "}\n",
    "for c in [64, 15]:\n",
    "    class_weight[c] = 2\n",
    "\n",
    "#print('Unique classes : ', classes)\n",
    "\n",
    "train_id = temp['object_id']\n",
    "del temp['object_id']\n",
    "# Compute weights\n",
    "w = y.value_counts()\n",
    "weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=51)\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "lgb_params = {\n",
    "'random_state':51,\n",
    "'device': 'cpu', \n",
    "'objective': 'multiclass', \n",
    "'num_class': 14, \n",
    "'boosting_type': 'gbdt', \n",
    "'n_jobs': -1, \n",
    "'max_depth': 7, \n",
    "'n_estimators': 1000, \n",
    "'subsample_freq': 2, \n",
    "'subsample_for_bin': 5000, \n",
    "'min_data_per_group': 100, \n",
    "'max_cat_to_onehot': 4, \n",
    "'cat_l2': 1.0, \n",
    "'cat_smooth': 59.5, \n",
    "'max_cat_threshold': 32, \n",
    "'metric_freq': 10, \n",
    "'verbosity': -1, \n",
    "'metric': 'multi_logloss', \n",
    "'xgboost_dart_mode': False, \n",
    "'uniform_drop': False, \n",
    "'colsample_bytree': 0.5, \n",
    "'drop_rate': 0.173, \n",
    "'learning_rate': 0.0267, \n",
    "'max_drop': 5, \n",
    "'min_child_samples': 10, \n",
    "'min_child_weight': 200.0, \n",
    "'min_split_gain': 0.1, \n",
    "'num_leaves': 7, \n",
    "'reg_alpha': 0.0, \n",
    "'reg_lambda': 0.00023, \n",
    "'skip_drop': 0.44, \n",
    "'subsample': 0.75}\n",
    "oof_preds = np.zeros((len(temp), np.unique(y).shape[0]))\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    trn_x, trn_y = temp.iloc[trn_], y.iloc[trn_]\n",
    "    val_x, val_y = temp.iloc[val_], y.iloc[val_]\n",
    "\n",
    "    trn_xa, trn_y, val_xa, val_y=smoteAdataset(trn_x.values, trn_y.values, val_x.values, val_y.values)\n",
    "    trn_x=pd.DataFrame(data=trn_xa, columns=trn_x.columns)\n",
    "    val_x=pd.DataFrame(data=val_xa, columns=val_x.columns)\n",
    "    \n",
    "    print(trn_x.shape,trn_y.shape,val_x.shape,val_y.shape)\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(\n",
    "        trn_x, trn_y,\n",
    "        eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "        eval_metric=lgb_multi_weighted_logloss,\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=50,\n",
    "        sample_weight=trn_y.map(weights)\n",
    "    )\n",
    "    oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "    loss_oof = multi_weighted_logloss(val_y, oof_preds[val_, :])\n",
    "    #loss_list.append(loss_oof)\n",
    "    print(fold_,loss_oof)\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = temp.columns\n",
    "    imp_df['gain'] = clf.feature_importances_\n",
    "    imp_df['fold'] = fold_ + 1\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "    clfs.append(clf)\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(y_true=y, y_preds=oof_preds))\n",
    "#final_dict[column_] = loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test = test_metadata_kaggle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_test['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test.fillna(0.0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 98) (3492890, 98)\n"
     ]
    }
   ],
   "source": [
    "print(temp.shape,temp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(temp.columns) == list(temp_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "CPU times: user 3h 8min 22s, sys: 23.2 s, total: 3h 8min 45s\n",
      "Wall time: 24min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred0 = pd.DataFrame()\n",
    "test_pred1 = pd.DataFrame()\n",
    "test_pred2 = pd.DataFrame()\n",
    "test_pred3 = pd.DataFrame()\n",
    "test_pred4 = pd.DataFrame()\n",
    "\n",
    "list_of_df = [test_pred0,test_pred1,test_pred2,test_pred3,test_pred4]\n",
    "\n",
    "for num,c in enumerate(clfs):\n",
    "    print(num)\n",
    "    for k in range(0,len(temp_test),500000):\n",
    "        test_pred = pd.DataFrame(c.predict_proba(temp_test[ k:k+500000] ))\n",
    "        list_of_df[num] = pd.concat([list_of_df[num],test_pred],axis=0)\n",
    "        del test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = pd.DataFrame()\n",
    "test_pred2 = (list_of_df[0] + list_of_df[1] + list_of_df[2] + list_of_df[3] + list_of_df[4])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 14)\n"
     ]
    }
   ],
   "source": [
    "print(test_pred2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pred2 = pd.DataFrame(np.random.rand(10,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.613339</td>\n",
       "      <td>0.099597</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.222354</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.058215</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.167974</td>\n",
       "      <td>0.051766</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.077005</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.040682</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.638965</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.011499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.012684</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.135556</td>\n",
       "      <td>0.090075</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.037354</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.160885</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.544588</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.011851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.051622</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.087818</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.496540</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.291865</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.040384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.092220</td>\n",
       "      <td>0.196609</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.671488</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000259  0.001050  0.000127  0.613339  0.099597  0.000296  0.222354   \n",
       "1  0.000163  0.008886  0.000166  0.167974  0.051766  0.000279  0.077005   \n",
       "2  0.000257  0.012684  0.000259  0.135556  0.090075  0.000408  0.037354   \n",
       "3  0.000281  0.001986  0.000299  0.051622  0.021756  0.000398  0.087818   \n",
       "4  0.000062  0.001839  0.000058  0.092220  0.196609  0.000139  0.021040   \n",
       "\n",
       "         7         8         9         10        11        12        13  \n",
       "0  0.000033  0.000115  0.002852  0.000276  0.058215  0.000156  0.001330  \n",
       "1  0.000154  0.000600  0.040682  0.001690  0.638965  0.000169  0.011499  \n",
       "2  0.002300  0.000548  0.160885  0.003061  0.544588  0.000174  0.011851  \n",
       "3  0.005267  0.000436  0.496540  0.001185  0.291865  0.000163  0.040384  \n",
       "4  0.000022  0.000102  0.016157  0.000100  0.671488  0.000054  0.000110  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_columns = ['object_id','class_6','class_15','class_16','class_42','class_52','class_53','class_62','class_64','class_65','class_67','class_88','class_90','class_92','class_95','class_99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2.columns = temp_columns[1:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnknown(data):\n",
    "    return ((((((data[\"mymedian\"]) + (((data[\"mymean\"]) / 2.0)))/2.0)) + (((((1.0) - (((data[\"mymax\"]) * (((data[\"mymax\"]) * (data[\"mymax\"]))))))) / 2.0)))/2.0)\n",
    "\n",
    "feats = ['class_6', 'class_15', 'class_16', 'class_42', 'class_52', 'class_53',\n",
    "         'class_62', 'class_64', 'class_65', 'class_67', 'class_88', 'class_90',\n",
    "         'class_92', 'class_95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "klm = pd.DataFrame()\n",
    "klm['mymean'] = test_pred2[feats].mean(axis=1)\n",
    "klm['mymedian'] = test_pred2[feats].median(axis=1)\n",
    "klm['mymax'] = test_pred2[feats].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2['class_99'] = getUnknown(klm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>492885</th>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.386889</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.145173</td>\n",
       "      <td>0.249667</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.096654</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.014446</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.099421</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.245200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492886</th>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.012543</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.051576</td>\n",
       "      <td>0.175610</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.021510</td>\n",
       "      <td>0.447852</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.030112</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.253879</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.238490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492887</th>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.038638</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.854522</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.070924</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.103272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492888</th>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.729113</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.134453</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.086651</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.028598</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.162133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492889</th>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.039832</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.289172</td>\n",
       "      <td>0.517296</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.036418</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.014750</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.100198</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.224456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class_6  class_15  class_16  class_42  class_52  class_53  class_62  \\\n",
       "492885  0.000221  0.386889  0.000399  0.145173  0.249667  0.000421  0.096654   \n",
       "492886  0.000315  0.012543  0.000334  0.051576  0.175610  0.000374  0.021510   \n",
       "492887  0.001076  0.038638  0.000232  0.854522  0.016455  0.000608  0.070924   \n",
       "492888  0.000084  0.729113  0.000109  0.134453  0.007923  0.000109  0.011622   \n",
       "492889  0.000166  0.039832  0.000185  0.289172  0.517296  0.000309  0.036418   \n",
       "\n",
       "        class_64  class_65  class_67  class_88  class_90  class_92  class_95  \\\n",
       "492885  0.000150  0.002551  0.014446  0.003441  0.099421  0.000201  0.000367   \n",
       "492886  0.447852  0.000694  0.030112  0.001282  0.253879  0.000317  0.003602   \n",
       "492887  0.000068  0.000353  0.001631  0.000889  0.012521  0.000292  0.001793   \n",
       "492888  0.086651  0.000358  0.000482  0.000135  0.028598  0.000071  0.000291   \n",
       "492889  0.000065  0.000349  0.014750  0.000566  0.100198  0.000186  0.000507   \n",
       "\n",
       "        class_99  \n",
       "492885  0.245200  \n",
       "492886  0.238490  \n",
       "492887  0.103272  \n",
       "492888  0.162133  \n",
       "492889  0.224456  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = test_pred2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 15) (3492890,)\n"
     ]
    }
   ],
   "source": [
    "print(test_pred2.shape,test_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16860    130787966\n",
       "16861    130787971\n",
       "16862    130787974\n",
       "16863    130788053\n",
       "16864    130788054\n",
       "Name: object_id, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_id.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.index == test_pred2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 120 ms, total: 222 ms\n",
      "Wall time: 221 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred = pd.concat([test_id,test_pred2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred[temp_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.613339</td>\n",
       "      <td>0.099597</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.222354</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.058215</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.201415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.167974</td>\n",
       "      <td>0.051766</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.077005</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.040682</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.638965</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>0.195032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.012684</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.135556</td>\n",
       "      <td>0.090075</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.037354</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.160885</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.544588</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>0.220414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.051622</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.087818</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.496540</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.291865</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.040384</td>\n",
       "      <td>0.229230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.092220</td>\n",
       "      <td>0.196609</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.671488</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.183267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id   class_6  class_15  class_16  class_42  class_52  class_53  \\\n",
       "0         13  0.000259  0.001050  0.000127  0.613339  0.099597  0.000296   \n",
       "1         14  0.000163  0.008886  0.000166  0.167974  0.051766  0.000279   \n",
       "2         17  0.000257  0.012684  0.000259  0.135556  0.090075  0.000408   \n",
       "3         23  0.000281  0.001986  0.000299  0.051622  0.021756  0.000398   \n",
       "4         34  0.000062  0.001839  0.000058  0.092220  0.196609  0.000139   \n",
       "\n",
       "   class_62  class_64  class_65  class_67  class_88  class_90  class_92  \\\n",
       "0  0.222354  0.000033  0.000115  0.002852  0.000276  0.058215  0.000156   \n",
       "1  0.077005  0.000154  0.000600  0.040682  0.001690  0.638965  0.000169   \n",
       "2  0.037354  0.002300  0.000548  0.160885  0.003061  0.544588  0.000174   \n",
       "3  0.087818  0.005267  0.000436  0.496540  0.001185  0.291865  0.000163   \n",
       "4  0.021040  0.000022  0.000102  0.016157  0.000100  0.671488  0.000054   \n",
       "\n",
       "   class_95  class_99  \n",
       "0  0.001330  0.201415  \n",
       "1  0.011499  0.195032  \n",
       "2  0.011851  0.220414  \n",
       "3  0.040384  0.229230  \n",
       "4  0.000110  0.183267  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 16)\n"
     ]
    }
   ],
   "source": [
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 960 ms, total: 1min 27s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred.to_csv('test_pred_20.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 1.06G/1.06G [40:34<00:00, 469kB/s]\n",
      "Successfully submitted to PLAsTiCC Astronomical Classification"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c PLAsTiCC-2018 -f test_pred_20.csv -m \"Message\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
