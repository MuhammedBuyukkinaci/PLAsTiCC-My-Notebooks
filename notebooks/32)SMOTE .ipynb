{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import lightgbm as lgb\n",
    "import itertools\n",
    "import pickle, gzip\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "np.warnings.filterwarnings('ignore')\n",
    "import dask.dataframe as dd\n",
    "import missingno as msno\n",
    "from pandasql import sqldf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always seed the randomness of this universe\n",
    "np.random.seed(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 97) (3492890, 96)\n",
      "CPU times: user 2min 36s, sys: 8.69 s, total: 2min 45s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_metadata_kaggle = dd.read_csv('mydata_train_metadata.csv')\n",
    "test_metadata_kaggle = dd.read_csv('mydata_test_metadata.csv')\n",
    "train_metadata_kaggle = train_metadata_kaggle.compute()\n",
    "test_metadata_kaggle = test_metadata_kaggle.compute()\n",
    "print(train_metadata_kaggle.shape,test_metadata_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_metadata_kaggle['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lgb_multi_weighted_logloss(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    # class_weights taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "    # https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "    # with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "    classes = [6, 15, 16, 42, 52, 53, 62, 64, 65, 67, 88, 90, 92, 95]\n",
    "    class_weight = {6: 1, 15: 2, 16: 1, 42: 1, 52: 1, 53: 1, 62: 1, 64: 2, 65: 1, 67: 1, 88: 1, 90: 1, 92: 1, 95: 1}\n",
    "    if len(np.unique(y_true)) > 14:\n",
    "        classes.append(99)\n",
    "        class_weight[99] = 2\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n",
    "\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weight[k] for k in sorted(class_weight.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return 'wloss', loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6316324136021252\n",
      "1 0.5974384829934377\n",
      "2 0.6560978939660322\n",
      "3 0.60199520197639\n",
      "4 0.6051021258382633\n",
      "MULTI WEIGHTED LOG LOSS : 0.61858 \n",
      "CPU times: user 11min 27s, sys: 2.11 s, total: 11min 29s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_dict = {}\n",
    "\n",
    "loss_list = []\n",
    "temp = train_metadata_kaggle.copy()\n",
    "#temp = temp.merge(train_metadata[['object_id',column_]],on = 'object_id',how = 'left')\n",
    "y = temp['target']\n",
    "del temp['target']\n",
    "classes = sorted(y.unique())\n",
    "\n",
    "# Taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "# https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "# with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "class_weight = {\n",
    "    c: 1 for c in classes\n",
    "}\n",
    "for c in [64, 15]:\n",
    "    class_weight[c] = 2\n",
    "\n",
    "#print('Unique classes : ', classes)\n",
    "\n",
    "train_id = temp['object_id']\n",
    "del temp['object_id']\n",
    "# Compute weights\n",
    "w = y.value_counts()\n",
    "weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=51)\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "lgb_params = {\n",
    "'random_state':51,\n",
    "'device': 'cpu', \n",
    "'objective': 'multiclass', \n",
    "'num_class': 14, \n",
    "'boosting_type': 'gbdt', \n",
    "'n_jobs': -1, \n",
    "'max_depth': 7, \n",
    "'n_estimators': 1000, \n",
    "'subsample_freq': 2, \n",
    "'subsample_for_bin': 5000, \n",
    "'min_data_per_group': 100, \n",
    "'max_cat_to_onehot': 4, \n",
    "'cat_l2': 1.0, \n",
    "'cat_smooth': 59.5, \n",
    "'max_cat_threshold': 32, \n",
    "'metric_freq': 10, \n",
    "'verbosity': -1, \n",
    "'metric': 'multi_logloss', \n",
    "'xgboost_dart_mode': False, \n",
    "'uniform_drop': False, \n",
    "'colsample_bytree': 0.5, \n",
    "'drop_rate': 0.173, \n",
    "'learning_rate': 0.0267, \n",
    "'max_drop': 5, \n",
    "'min_child_samples': 10, \n",
    "'min_child_weight': 100.0, \n",
    "'min_split_gain': 0.1, \n",
    "'num_leaves': 7, \n",
    "'reg_alpha': 0.1, \n",
    "'reg_lambda': 0.00023, \n",
    "'skip_drop': 0.44, \n",
    "'subsample': 0.75}\n",
    "oof_preds = np.zeros((len(temp), np.unique(y).shape[0]))\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    trn_x, trn_y = temp.iloc[trn_], y.iloc[trn_]\n",
    "    val_x, val_y = temp.iloc[val_], y.iloc[val_]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(\n",
    "        trn_x, trn_y,\n",
    "        eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "        eval_metric=lgb_multi_weighted_logloss,\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=50,\n",
    "        sample_weight=trn_y.map(weights)\n",
    "    )\n",
    "    oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "    loss_oof = multi_weighted_logloss(val_y, oof_preds[val_, :])\n",
    "    #loss_list.append(loss_oof)\n",
    "    print(fold_,loss_oof)\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = temp.columns\n",
    "    imp_df['gain'] = clf.feature_importances_\n",
    "    imp_df['fold'] = fold_ + 1\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "    clfs.append(clf)\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(y_true=y, y_preds=oof_preds))\n",
    "#final_dict[column_] = loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify to work with kfold\n",
    "#def smoteAdataset(Xig, yig, test_size=0.2, random_state=0):\n",
    "def smoteAdataset(Xig_train, yig_train, Xig_test, yig_test):\n",
    "    \n",
    "        \n",
    "    sm=SMOTE(random_state=51)\n",
    "    Xig_train_res, yig_train_res = sm.fit_sample(Xig_train, yig_train.ravel())\n",
    "\n",
    "        \n",
    "    return Xig_train_res, pd.Series(yig_train_res), Xig_test, pd.Series(yig_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25900, 95) (25900,) (1574, 95) (1574,)\n",
      "0 0.5806310687793009\n",
      "(25900, 95) (25900,) (1572, 95) (1572,)\n",
      "1 0.6020714634772362\n",
      "(25900, 95) (25900,) (1571, 95) (1571,)\n",
      "2 0.6698644413009827\n",
      "(25914, 95) (25914,) (1567, 95) (1567,)\n",
      "3 0.5952845334850775\n",
      "(25914, 95) (25914,) (1564, 95) (1564,)\n",
      "4 0.6108895061583888\n",
      "MULTI WEIGHTED LOG LOSS : 0.61165 \n",
      "CPU times: user 29min 20s, sys: 5.25 s, total: 29min 26s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_dict = {}\n",
    "\n",
    "loss_list = []\n",
    "temp = train_metadata_kaggle.copy()\n",
    "temp.fillna(0, inplace=True)\n",
    "#temp = temp.merge(train_metadata[['object_id',column_]],on = 'object_id',how = 'left')\n",
    "y = temp['target']\n",
    "del temp['target']\n",
    "classes = sorted(y.unique())\n",
    "\n",
    "# Taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "# https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "# with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "class_weight = {\n",
    "    c: 1 for c in classes\n",
    "}\n",
    "for c in [64, 15]:\n",
    "    class_weight[c] = 2\n",
    "\n",
    "#print('Unique classes : ', classes)\n",
    "\n",
    "train_id = temp['object_id']\n",
    "del temp['object_id']\n",
    "# Compute weights\n",
    "w = y.value_counts()\n",
    "weights = {i : np.sum(w) / w[i] for i in w.index}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=51)\n",
    "clfs = []\n",
    "importances = pd.DataFrame()\n",
    "lgb_params = {\n",
    "'random_state':51,\n",
    "'device': 'cpu', \n",
    "'objective': 'multiclass', \n",
    "'num_class': 14, \n",
    "'boosting_type': 'gbdt', \n",
    "'n_jobs': -1, \n",
    "'max_depth': 7, \n",
    "'n_estimators': 1000, \n",
    "'subsample_freq': 2, \n",
    "'subsample_for_bin': 5000, \n",
    "'min_data_per_group': 100, \n",
    "'max_cat_to_onehot': 4, \n",
    "'cat_l2': 1.0, \n",
    "'cat_smooth': 59.5, \n",
    "'max_cat_threshold': 32, \n",
    "'metric_freq': 10, \n",
    "'verbosity': -1, \n",
    "'metric': 'multi_logloss', \n",
    "'xgboost_dart_mode': False, \n",
    "'uniform_drop': False, \n",
    "'colsample_bytree': 0.5, \n",
    "'drop_rate': 0.173, \n",
    "'learning_rate': 0.0267, \n",
    "'max_drop': 5, \n",
    "'min_child_samples': 10, \n",
    "'min_child_weight': 100.0, \n",
    "'min_split_gain': 0.1, \n",
    "'num_leaves': 7, \n",
    "'reg_alpha': 0.1, \n",
    "'reg_lambda': 0.00023, \n",
    "'skip_drop': 0.44, \n",
    "'subsample': 0.75}\n",
    "oof_preds = np.zeros((len(temp), np.unique(y).shape[0]))\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    trn_x, trn_y = temp.iloc[trn_], y.iloc[trn_]\n",
    "    val_x, val_y = temp.iloc[val_], y.iloc[val_]\n",
    "\n",
    "    trn_xa, trn_y, val_xa, val_y=smoteAdataset(trn_x.values, trn_y.values, val_x.values, val_y.values)\n",
    "    trn_x=pd.DataFrame(data=trn_xa, columns=trn_x.columns)\n",
    "    val_x=pd.DataFrame(data=val_xa, columns=val_x.columns)\n",
    "    \n",
    "    print(trn_x.shape,trn_y.shape,val_x.shape,val_y.shape)\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(\n",
    "        trn_x, trn_y,\n",
    "        eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "        eval_metric=lgb_multi_weighted_logloss,\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=50,\n",
    "        sample_weight=trn_y.map(weights)\n",
    "    )\n",
    "    oof_preds[val_, :] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)\n",
    "    loss_oof = multi_weighted_logloss(val_y, oof_preds[val_, :])\n",
    "    #loss_list.append(loss_oof)\n",
    "    print(fold_,loss_oof)\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = temp.columns\n",
    "    imp_df['gain'] = clf.feature_importances_\n",
    "    imp_df['fold'] = fold_ + 1\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "    clfs.append(clf)\n",
    "print('MULTI WEIGHTED LOG LOSS : %.5f ' % multi_weighted_logloss(y_true=y, y_preds=oof_preds))\n",
    "#final_dict[column_] = loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test = test_metadata_kaggle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp_test['object_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test.fillna(0.0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7848, 95) (3492890, 95)\n"
     ]
    }
   ],
   "source": [
    "print(temp.shape,temp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(temp.columns) == list(temp_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "CPU times: user 3h 16min 10s, sys: 34.5 s, total: 3h 16min 45s\n",
      "Wall time: 26min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred0 = pd.DataFrame()\n",
    "test_pred1 = pd.DataFrame()\n",
    "test_pred2 = pd.DataFrame()\n",
    "test_pred3 = pd.DataFrame()\n",
    "test_pred4 = pd.DataFrame()\n",
    "\n",
    "list_of_df = [test_pred0,test_pred1,test_pred2,test_pred3,test_pred4]\n",
    "\n",
    "for num,c in enumerate(clfs):\n",
    "    print(num)\n",
    "    for k in range(0,len(temp_test),500000):\n",
    "        test_pred = pd.DataFrame(c.predict_proba(temp_test[ k:k+500000] ))\n",
    "        list_of_df[num] = pd.concat([list_of_df[num],test_pred],axis=0)\n",
    "        del test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = pd.DataFrame()\n",
    "test_pred2 = (list_of_df[0] + list_of_df[1] + list_of_df[2] + list_of_df[3] + list_of_df[4])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 14)\n"
     ]
    }
   ],
   "source": [
    "print(test_pred2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2[14] = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = test_pred2 / 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = test_pred2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_columns = ['object_id','class_6','class_15','class_16','class_42','class_52','class_53','class_62','class_64','class_65','class_67','class_88','class_90','class_92','class_95','class_99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2.columns = temp_columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 15) (3492890,)\n"
     ]
    }
   ],
   "source": [
    "print(test_pred2.shape,test_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43036    130787966\n",
       "43037    130787971\n",
       "43038    130787974\n",
       "43039    130788053\n",
       "43040    130788054\n",
       "Name: object_id, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_id.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id.index == test_pred2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91.6 ms, sys: 130 ms, total: 222 ms\n",
      "Wall time: 221 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred = pd.concat([test_id,test_pred2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred[temp_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_62</th>\n",
       "      <th>class_64</th>\n",
       "      <th>class_65</th>\n",
       "      <th>class_67</th>\n",
       "      <th>class_88</th>\n",
       "      <th>class_90</th>\n",
       "      <th>class_92</th>\n",
       "      <th>class_95</th>\n",
       "      <th>class_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.529505</td>\n",
       "      <td>0.090287</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.200498</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.045692</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.125341</td>\n",
       "      <td>0.047776</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.069581</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.037956</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.571482</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.107580</td>\n",
       "      <td>0.097682</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.033589</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.156107</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.446953</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.064814</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.448367</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.261123</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.032999</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.077916</td>\n",
       "      <td>0.163340</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.010836</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.598788</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id   class_6  class_15  class_16  class_42  class_52  class_53  \\\n",
       "0         13  0.000103  0.000804  0.000058  0.529505  0.090287  0.000127   \n",
       "1         14  0.000091  0.006411  0.000085  0.125341  0.047776  0.000143   \n",
       "2         17  0.000131  0.009884  0.000131  0.107580  0.097682  0.000205   \n",
       "3         23  0.000133  0.001833  0.000124  0.036626  0.018691  0.000192   \n",
       "4         34  0.000030  0.001527  0.000028  0.077916  0.163340  0.000063   \n",
       "\n",
       "   class_62  class_64  class_65  class_67  class_88  class_90  class_92  \\\n",
       "0  0.200498  0.000017  0.000059  0.001475  0.000134  0.045692  0.000067   \n",
       "1  0.069581  0.000098  0.000283  0.037956  0.000807  0.571482  0.000090   \n",
       "2  0.033589  0.002154  0.000264  0.156107  0.001494  0.446953  0.000090   \n",
       "3  0.064814  0.003879  0.000205  0.448367  0.000497  0.261123  0.000083   \n",
       "4  0.016816  0.000012  0.000049  0.010836  0.000045  0.598788  0.000026   \n",
       "\n",
       "   class_95  class_99  \n",
       "0  0.000741  0.130435  \n",
       "1  0.009420  0.130435  \n",
       "2  0.013300  0.130435  \n",
       "3  0.032999  0.130435  \n",
       "4  0.000088  0.130435  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3492890, 16)\n"
     ]
    }
   ],
   "source": [
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 976 ms, total: 1min 27s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred.to_csv('test_pred_17.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
